{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# WHO Dataset Exploration\\n\",\n",
    "    \"Explore and analyze the WHO disease dataset\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import json\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load data\\n\",\n",
    "    \"with open('../data/raw/who_dataset.json', 'r') as f:\\n\",\n",
    "    \"    data = json.load(f)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Total documents: {len(data)}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nSample document keys: {list(data[0].keys())}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create DataFrame\\n\",\n",
    "    \"df = pd.DataFrame(data)\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Analyze text length distribution\\n\",\n",
    "    \"df['total_length'] = df.apply(\\n\",\n",
    "    \"    lambda row: sum(len(str(row[col])) for col in ['key_facts', 'overview', 'symptoms', 'treatment']),\\n\",\n",
    "    \"    axis=1\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"plt.hist(df['total_length'], bins=30, edgecolor='black')\\n\",\n",
    "    \"plt.xlabel('Total Text Length')\\n\",\n",
    "    \"plt.ylabel('Frequency')\\n\",\n",
    "    \"plt.title('Distribution of Document Lengths')\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check field completeness\\n\",\n",
    "    \"fields = ['key_facts', 'overview', 'symptoms', 'causes', 'treatment', 'self_care']\\n\",\n",
    "    \"completeness = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"for field in fields:\\n\",\n",
    "    \"    non_empty = df[field].notna() & (df[field] != '')\\n\",\n",
    "    \"    completeness[field] = non_empty.sum() / len(df) * 100\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"plt.bar(completeness.keys(), completeness.values())\\n\",\n",
    "    \"plt.xlabel('Field')\\n\",\n",
    "    \"plt.ylabel('Completeness (%)')\\n\",\n",
    "    \"plt.title('Field Completeness Analysis')\\n\",\n",
    "    \"plt.xticks(rotation=45)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# WHO Dataset Exploration\\n\",\n",
    "    \"## Comprehensive analysis of the WHO disease fact sheets dataset\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook explores:\\n\",\n",
    "    \"- Dataset statistics and completeness\\n\",\n",
    "    \"- Text length distributions\\n\",\n",
    "    \"- Field coverage analysis\\n\",\n",
    "    \"- Sample data inspection\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"from collections import Counter\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set style\\n\",\n",
    "    \"sns.set_style('whitegrid')\\n\",\n",
    "    \"plt.rcParams['figure.figsize'] = (12, 6)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"✓ Imports successful\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Load Dataset\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load WHO dataset\\n\",\n",
    "    \"data_path = Path('../data/raw/who_dataset.json')\\n\",\n",
    "    \"\\n\",\n",
    "    \"if not data_path.exists():\\n\",\n",
    "    \"    print(\\\"❌ Dataset not found! Please run scraper first:\\\")\\n\",\n",
    "    \"    print(\\\"   python scripts/scrape_who_data.py\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    with open(data_path, 'r', encoding='utf-8') as f:\\n\",\n",
    "    \"        data = json.load(f)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"✓ Loaded {len(data)} documents\\\")\\n\",\n",
    "    \"    print(f\\\"✓ Sample keys: {list(data[0].keys())}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Basic Statistics\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Convert to DataFrame\\n\",\n",
    "    \"df = pd.DataFrame(data)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Dataset Shape:\\\", df.shape)\\n\",\n",
    "    \"print(\\\"\\\\nColumns:\\\")\\n\",\n",
    "    \"for col in df.columns:\\n\",\n",
    "    \"    print(f\\\"  - {col}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display sample diseases\\n\",\n",
    "    \"print(\\\"Sample Diseases:\\\")\\n\",\n",
    "    \"for i, name in enumerate(df['name'].head(10), 1):\\n\",\n",
    "    \"    print(f\\\"{i:2d}. {name}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Field Completeness Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Calculate completeness for each field\\n\",\n",
    "    \"fields = ['key_facts', 'overview', 'symptoms', 'causes', 'treatment', 'self_care', 'impact', 'who_response', 'reference']\\n\",\n",
    "    \"\\n\",\n",
    "    \"completeness = {}\\n\",\n",
    "    \"for field in fields:\\n\",\n",
    "    \"    non_empty = df[field].notna() & (df[field].str.strip() != '')\\n\",\n",
    "    \"    completeness[field] = (non_empty.sum() / len(df)) * 100\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create DataFrame for better visualization\\n\",\n",
    "    \"completeness_df = pd.DataFrame({\\n\",\n",
    "    \"    'Field': list(completeness.keys()),\\n\",\n",
    "    \"    'Completeness (%)': list(completeness.values())\\n\",\n",
    "    \"}).sort_values('Completeness (%)', ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(completeness_df.to_string(index=False))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize completeness\\n\",\n",
    "    \"plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(completeness_df)))\\n\",\n",
    "    \"bars = plt.bar(completeness_df['Field'], completeness_df['Completeness (%)'], color=colors)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.xlabel('Field', fontsize=12)\\n\",\n",
    "    \"plt.ylabel('Completeness (%)', fontsize=12)\\n\",\n",
    "    \"plt.title('Field Completeness Analysis', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"plt.xticks(rotation=45, ha='right')\\n\",\n",
    "    \"plt.ylim(0, 105)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add percentage labels on bars\\n\",\n",
    "    \"for bar in bars:\\n\",\n",
    "    \"    height = bar.get_height()\\n\",\n",
    "    \"    plt.text(bar.get_x() + bar.get_width()/2., height,\\n\",\n",
    "    \"             f'{height:.1f}%',\\n\",\n",
    "    \"             ha='center', va='bottom', fontsize=9)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Text Length Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Calculate text lengths\\n\",\n",
    "    \"for field in fields:\\n\",\n",
    "    \"    df[f'{field}_length'] = df[field].fillna('').str.len()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Total content length\\n\",\n",
    "    \"df['total_length'] = df[[f'{field}_length' for field in fields]].sum(axis=1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Word count\\n\",\n",
    "    \"df['word_count'] = df.apply(\\n\",\n",
    "    \"    lambda row: sum(len(str(row[field]).split()) for field in fields),\\n\",\n",
    "    \"    axis=1\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Text Length Statistics:\\\")\\n\",\n",
    "    \"print(df[['total_length', 'word_count']].describe())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Distribution of document lengths\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 2, figsize=(14, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Character count distribution\\n\",\n",
    "    \"axes[0].hist(df['total_length'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)\\n\",\n",
    "    \"axes[0].axvline(df['total_length'].median(), color='red', linestyle='--', label=f'Median: {df[\\\"total_length\\\"].median():.0f}')\\n\",\n",
    "    \"axes[0].set_xlabel('Total Characters', fontsize=11)\\n\",\n",
    "    \"axes[0].set_ylabel('Frequency', fontsize=11)\\n\",\n",
    "    \"axes[0].set_title('Distribution of Document Lengths (Characters)', fontsize=12, fontweight='bold')\\n\",\n",
    "    \"axes[0].legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Word count distribution\\n\",\n",
    "    \"axes[1].hist(df['word_count'], bins=30, color='lightcoral', edgecolor='black', alpha=0.7)\\n\",\n",
    "    \"axes[1].axvline(df['word_count'].median(), color='red', linestyle='--', label=f'Median: {df[\\\"word_count\\\"].median():.0f}')\\n\",\n",
    "    \"axes[1].set_xlabel('Total Words', fontsize=11)\\n\",\n",
    "    \"axes[1].set_ylabel('Frequency', fontsize=11)\\n\",\n",
    "    \"axes[1].set_title('Distribution of Document Lengths (Words)', fontsize=12, fontweight='bold')\\n\",\n",
    "    \"axes[1].legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Field-wise length distribution\\n\",\n",
    "    \"length_cols = [f'{field}_length' for field in fields]\\n\",\n",
    "    \"field_lengths = df[length_cols].mean().sort_values(ascending=False)\\n\",\n",
    "    \"field_lengths.index = [col.replace('_length', '').replace('_', ' ').title() for col in field_lengths.index]\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"colors = plt.cm.plasma(np.linspace(0.2, 0.8, len(field_lengths)))\\n\",\n",
    "    \"bars = plt.barh(field_lengths.index, field_lengths.values, color=colors)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.xlabel('Average Character Count', fontsize=12)\\n\",\n",
    "    \"plt.ylabel('Field', fontsize=12)\\n\",\n",
    "    \"plt.title('Average Text Length by Field', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add value labels\\n\",\n",
    "    \"for i, bar in enumerate(bars):\\n\",\n",
    "    \"    width = bar.get_width()\\n\",\n",
    "    \"    plt.text(width, bar.get_y() + bar.get_height()/2.,\\n\",\n",
    "    \"             f'{width:.0f}',\\n\",\n",
    "    \"             ha='left', va='center', fontsize=9, fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Content Quality Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Documents with complete information (all major fields filled)\\n\",\n",
    "    \"major_fields = ['key_facts', 'overview', 'symptoms', 'treatment']\\n\",\n",
    "    \"df['is_complete'] = df[major_fields].notna().all(axis=1) & \\\\\\n\",\n",
    "    \"                    (df[major_fields] != '').all(axis=1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"complete_count = df['is_complete'].sum()\\n\",\n",
    "    \"complete_pct = (complete_count / len(df)) * 100\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Documents with complete major fields: {complete_count}/{len(df)} ({complete_pct:.1f}%)\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize\\n\",\n",
    "    \"fig, ax = plt.subplots(figsize=(8, 8))\\n\",\n",
    "    \"sizes = [complete_count, len(df) - complete_count]\\n\",\n",
    "    \"labels = [f'Complete\\\\n({complete_count})', f'Incomplete\\\\n({len(df) - complete_count})']\\n\",\n",
    "    \"colors = ['#2ecc71', '#e74c3c']\\n\",\n",
    "    \"explode = (0.05, 0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"ax.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%',\\n\",\n",
    "    \"       startangle=90, explode=explode, textprops={'fontsize': 12})\\n\",\n",
    "    \"ax.set_title('Document Completeness (Major Fields)', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Sample Document Inspection\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Display a complete sample document\\n\",\n",
    "    \"if complete_count > 0:\\n\",\n",
    "    \"    sample = df[df['is_complete']].iloc[0]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"=\\\"*80)\\n\",\n",
    "    \"    print(f\\\"SAMPLE DOCUMENT: {sample['name']}\\\")\\n\",\n",
    "    \"    print(\\\"=\\\"*80)\\n\",\n",
    "    \"    print(f\\\"\\\\nURL: {sample['url']}\\\")\\n\",\n",
    "    \"    print(f\\\"\\\\nTotal Length: {sample['total_length']} characters\\\")\\n\",\n",
    "    \"    print(f\\\"Word Count: {sample['word_count']} words\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for field in fields:\\n\",\n",
    "    \"        content = sample[field]\\n\",\n",
    "    \"        if content and content.strip():\\n\",\n",
    "    \"            print(f\\\"\\\\n{'='*80}\\\")\\n\",\n",
    "    \"            print(f\\\"{field.upper().replace('_', ' ')}:\\\")\\n\",\n",
    "    \"            print(f\\\"{'='*80}\\\")\\n\",\n",
    "    \"            # Truncate if too long\\n\",\n",
    "    \"            if len(content) > 500:\\n\",\n",
    "    \"                print(content[:500] + \\\"...\\\")\\n\",\n",
    "    \"                print(f\\\"\\\\n[Truncated. Full length: {len(content)} characters]\\\")\\n\",\n",
    "    \"            else:\\n\",\n",
    "    \"                print(content)\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"No complete documents found in dataset\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Top Diseases by Content\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Top 10 diseases by content length\\n\",\n",
    "    \"top_diseases = df.nlargest(10, 'total_length')[['name', 'total_length', 'word_count']]\\n\",\n",
    "    \"top_diseases.index = range(1, len(top_diseases) + 1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Top 10 Diseases by Content Length:\\\")\\n\",\n",
    "    \"print(top_diseases.to_string())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Summary Statistics\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*80)\\n\",\n",
    "    \"print(\\\"DATASET SUMMARY\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*80)\\n\",\n",
    "    \"print(f\\\"Total Documents: {len(df)}\\\")\\n\",\n",
    "    \"print(f\\\"Complete Documents: {complete_count} ({complete_pct:.1f}%)\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nAverage Document Length: {df['total_length'].mean():.0f} characters\\\")\\n\",\n",
    "    \"print(f\\\"Average Word Count: {df['word_count'].mean():.0f} words\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nField Completeness (Top 3):\\\")\\n\",\n",
    "    \"for i, row in completeness_df.head(3).iterrows():\\n\",\n",
    "    \"    print(f\\\"  {row['Field']:15s}: {row['Completeness (%)']:5.1f}%\\\")\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*80)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Export Summary\\n\",\n",
    "    \"Save exploration results for reference\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create summary dictionary\\n\",\n",
    "    \"summary = {\\n\",\n",
    "    \"    'total_documents': len(df),\\n\",\n",
    "    \"    'complete_documents': int(complete_count),\\n\",\n",
    "    \"    'avg_length_chars': float(df['total_length'].mean()),\\n\",\n",
    "    \"    'avg_word_count': float(df['word_count'].mean()),\\n\",\n",
    "    \"    'field_completeness': completeness,\\n\",\n",
    "    \"    'top_diseases': df.nlargest(10, 'total_length')['name'].tolist()\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save to JSON\\n\",\n",
    "    \"output_path = Path('../data/processed/exploration_summary.json')\\n\",\n",
    "    \"output_path.parent.mkdir(parents=True, exist_ok=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"with open(output_path, 'w') as f:\\n\",\n",
    "    \"    json.dump(summary, f, indent=2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"✓ Summary saved to {output_path}\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
